{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preparing the PCam data for training deep learning models using tensorflow dataset (tfds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\caspe\\anaconda3\\anaconda4\\envs\\ENV_NAME\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"   # Delete if you have GPU's available\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    " \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, losses\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function that splits images and labels and one-hot-encodes the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sample(sample):\n",
    "    image, label = sample['image'], sample['label']  \n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sample(sample):\n",
    "    image, label = sample['image'], sample['label']  \n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image, image  # Use the image itself as the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Corrected file path with escaped backslashes and a missing comma\n",
    "ds1, ds2, ds3 = tfds.load('patch_camelyon',\n",
    "                         split=['train[:20%]', 'test[:5%]', 'validation[:5%]'],\n",
    "                         data_dir=\"C:\\\\Users\\\\caspe\\\\OneDrive\\\\Skrivebord\\\\AvendtML_Eksamen\",\n",
    "                         download=False,\n",
    "                         shuffle_files=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we simple transform the data (by the function convert sample described previously) and getting ready for training by splitting it into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: <_BatchDataset element_spec=(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None))>\n",
      "Shape of the validation data: <_BatchDataset element_spec=(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None))>\n",
      "Shape of the testing data: <_BatchDataset element_spec=(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "train_dataset       = ds1.map(convert_sample).batch(32)\n",
    "validation_dataset  = ds3.map(convert_sample).batch(32)\n",
    "test_dataset        = ds2.map(convert_sample).batch(32)\n",
    "print(\"Shape of the training data:\", train_dataset)\n",
    "print(\"Shape of the validation data:\", validation_dataset)\n",
    "print(\"Shape of the testing data:\", test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\caspe\\anaconda3\\anaconda4\\envs\\ENV_NAME\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\caspe\\anaconda3\\anaconda4\\envs\\ENV_NAME\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definition of the Autoencoder model as a subclass of the TensorFlow Model class\n",
    "\n",
    "class SimpleAutoencoder(Model):\n",
    "\tdef __init__(self,latent_dimensions , data_shape):\n",
    "\t\tsuper(SimpleAutoencoder, self).__init__()\n",
    "\t\tself.latent_dimensions = latent_dimensions\n",
    "\t\tself.data_shape = data_shape\n",
    "\n",
    "\t\t# Encoder architecture using a Sequential model\n",
    "\t\tself.encoder = tf.keras.Sequential([\n",
    "\t\t\tlayers.Flatten(),\n",
    "\t\t\tlayers.Dense(latent_dimensions, activation='relu'),\n",
    "\t\t])\n",
    "\n",
    "\t\t# Decoder architecture using another Sequential model\n",
    "\t\tself.decoder = tf.keras.Sequential([\n",
    "\t\t\tlayers.Dense(tf.math.reduce_prod(data_shape), activation='sigmoid'),\n",
    "\t\t\tlayers.Reshape(data_shape)\n",
    "\t\t])\n",
    "\n",
    "\t# Forward pass method defining the encoding and decoding steps\n",
    "\tdef call(self, input_data):\n",
    "\t\tencoded_data = self.encoder(input_data)\n",
    "\t\tdecoded_data = self.decoder(encoded_data)\n",
    "\t\treturn decoded_data\n",
    "\n",
    "# Extracting shape information from the testing dataset\n",
    "input_data_shape = next(iter(test_dataset))[0].shape[1:]\n",
    "\n",
    "# Specifying the dimensionality of the latent space\n",
    "latent_dimensions = 64\n",
    "\n",
    "# Creating an instance of the SimpleAutoencoder model\n",
    "simple_autoencoder = SimpleAutoencoder(latent_dimensions, input_data_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1639/1639 [==============================] - 144s 87ms/step - loss: 0.0407 - val_loss: 0.0433\n",
      "Epoch 2/10\n",
      "1639/1639 [==============================] - 131s 80ms/step - loss: 0.0403 - val_loss: 0.0429\n",
      "Epoch 3/10\n",
      "1639/1639 [==============================] - 163s 99ms/step - loss: 0.0398 - val_loss: 0.0434\n",
      "Epoch 4/10\n",
      "1639/1639 [==============================] - 136s 83ms/step - loss: 0.0395 - val_loss: 0.0421\n",
      "Epoch 5/10\n",
      "1639/1639 [==============================] - 122s 74ms/step - loss: 0.0392 - val_loss: 0.0426\n",
      "Epoch 6/10\n",
      "1639/1639 [==============================] - 109s 67ms/step - loss: 0.0390 - val_loss: 0.0422\n",
      "Epoch 7/10\n",
      "1639/1639 [==============================] - 110s 67ms/step - loss: 0.0388 - val_loss: 0.0418\n",
      "Epoch 8/10\n",
      "1639/1639 [==============================] - 108s 66ms/step - loss: 0.0387 - val_loss: 0.0414\n",
      "Epoch 9/10\n",
      "1639/1639 [==============================] - 103s 63ms/step - loss: 0.0386 - val_loss: 0.0412\n",
      "Epoch 10/10\n",
      "1639/1639 [==============================] - 121s 74ms/step - loss: 0.0384 - val_loss: 0.0414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2118c7e4890>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model compilation\n",
    "simple_autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "# Training the model\n",
    "simple_autoencoder.fit(train_dataset, \n",
    "                       epochs=10,\n",
    "                       validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'sequential' (type Sequential).\n\nInputs to a layer should be tensors. Got '<_BatchDataset element_spec=(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None))>' (of type <class 'tensorflow.python.data.ops.batch_op._BatchDataset'>) as input for layer 'flatten'.\n\nCall arguments received by layer 'sequential' (type Sequential):\n  • inputs=<_BatchDataset element_spec=(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None))>\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoded_imgs \u001b[38;5;241m=\u001b[39m simple_autoencoder\u001b[38;5;241m.\u001b[39mencoder(test_dataset)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      2\u001b[0m decoded_imgs \u001b[38;5;241m=\u001b[39m simple_autoencoder\u001b[38;5;241m.\u001b[39mdecoder(encoded_imgs)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\caspe\\anaconda3\\anaconda4\\envs\\ENV_NAME\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\caspe\\anaconda3\\anaconda4\\envs\\ENV_NAME\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py:213\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# tensor-like objects that may be passed. The most common kind of\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# invalid type we are guarding for is a Layer instance (Functional API),\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# which does not have a `shape` attribute.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) as input for layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'sequential' (type Sequential).\n\nInputs to a layer should be tensors. Got '<_BatchDataset element_spec=(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None))>' (of type <class 'tensorflow.python.data.ops.batch_op._BatchDataset'>) as input for layer 'flatten'.\n\nCall arguments received by layer 'sequential' (type Sequential):\n  • inputs=<_BatchDataset element_spec=(TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name=None))>\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amlfall22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3cedec8935a2c28d6fd602c3007747750e2af1c4c937c29fac0d323bf1b544b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
